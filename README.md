# OpenAI å…¼å®¹ Gemini é€‚é…å™¨ + åŸç”Ÿ Gemini API

ä¸€ä¸ªé«˜æ€§èƒ½åå‘ä»£ç†æœåŠ¡ï¼Œæä¾›åŒé‡ API æ¥å£ï¼šå°† Google Gemini API è½¬æ¢ä¸ºå®Œå…¨å…¼å®¹ OpenAI API çš„æ¥å£ï¼ŒåŒæ—¶æ”¯æŒåŸç”Ÿ Gemini API æ ¼å¼ã€‚å†…ç½®æ™ºèƒ½å¯†é’¥è½®è¯¢ã€è‡ªåŠ¨æ•…éšœè½¬ç§»å’Œå†·å´æœºåˆ¶ï¼Œæä¾›ç¨³å®šå¯é çš„å¤§æ¨¡å‹æ¥å…¥æœåŠ¡ã€‚

## âœ¨ ä¸»è¦åŠŸèƒ½

### ğŸ”„ åŒé‡ API æ”¯æŒ
- ğŸ¤– **å®Œæ•´ OpenAI API å…¼å®¹** - æ”¯æŒ `/v1/chat/completions`ã€æµå¼å“åº”ã€å·¥å…·è°ƒç”¨
- ğŸ†• **åŸç”Ÿ Gemini API æ¥å£** - æ”¯æŒ `/gemini/v1beta/models/{model}:generateContent` å’Œæµå¼å“åº”
- ğŸ”§ **ç»Ÿä¸€å¯†é’¥ç®¡ç†** - ä¸¤å¥— API ä½¿ç”¨ç›¸åŒçš„å¯†é’¥æ± å’Œè½®è¯¢æœºåˆ¶

### ğŸ”‘ æ™ºèƒ½ç®¡ç†
- ğŸ”„ **æ™ºèƒ½å¯†é’¥ç®¡ç†** - è‡ªåŠ¨è½®è¯¢å¤šä¸ª API å¯†é’¥ï¼Œå¤±è´¥è‡ªåŠ¨åˆ‡æ¢
- âš¡ **é«˜æ€§èƒ½å“åº”** - çœŸæ­£çš„æµå¼è¾“å‡ºï¼Œä¼ä¸šçº§ç¼“å­˜æœºåˆ¶
- ğŸ›¡ï¸ **å®‰å…¨è®¤è¯** - å®¢æˆ·ç«¯å¯†é’¥å’Œç®¡ç†å¯†é’¥åŒé‡ä¿æŠ¤
- ğŸ“Š **å®æ—¶ç›‘æ§** - å¯†é’¥çŠ¶æ€ã€æ€§èƒ½æŒ‡æ ‡ã€å¥åº·æ£€æŸ¥
- ğŸ³ **Docker éƒ¨ç½²** - ä¸€é”®å¯åŠ¨ï¼Œæ— éœ€å¤æ‚é…ç½®

## ğŸ“‹ å®‰è£…è¦æ±‚

- **Docker** å’Œ **Docker Compose** 
- **Google Gemini API å¯†é’¥** ([ç”³è¯·åœ°å€](https://aistudio.google.com/app/apikey))
- **Git** ç”¨äºè·å–æºç 

## ğŸš€ å¿«é€Ÿå®‰è£…

### 1. è·å–æºç 

```bash
git clone https://github.com/tellerlin/gemini-converter.git
cd gemini-converter
```

### 2. é…ç½®å¯†é’¥

å¤åˆ¶é…ç½®æ¨¡æ¿å¹¶ç¼–è¾‘ï¼š

```bash
cp .env.example .env
nano .env  # æˆ–ä½¿ç”¨ä½ å–œæ¬¢çš„ç¼–è¾‘å™¨
```

**å¿…é¡»é…ç½®çš„å‚æ•°ï¼š**

```bash
# Gemini API å¯†é’¥ï¼ˆå¤šä¸ªç”¨é€—å·åˆ†éš”ï¼‰
GEMINI_API_KEYS=your-gemini-key1,your-gemini-key2

# å®¢æˆ·ç«¯è®¿é—®å¯†é’¥ï¼ˆå»ºè®®ä½¿ç”¨ openssl rand -hex 32 ç”Ÿæˆï¼‰
SECURITY_ADAPTER_API_KEYS=your-secure-client-key

# ç®¡ç†å‘˜å¯†é’¥ï¼ˆå¯é€‰ï¼Œç”¨äºç®¡ç†åŠŸèƒ½ï¼‰
SECURITY_ADMIN_API_KEYS=your-secure-admin-key
```

### 3. å¯åŠ¨æœåŠ¡

```bash
docker-compose up -d --build
```

### 4. éªŒè¯è¿è¡Œ

```bash
# æ£€æŸ¥å®¹å™¨çŠ¶æ€
docker-compose ps

# æŸ¥çœ‹å¯åŠ¨æ—¥å¿—
docker-compose logs --tail 20

# æµ‹è¯•æœåŠ¡
curl http://localhost:8000/health
```

å¦‚æœçœ‹åˆ°ç±»ä¼¼ `"status": "healthy"` çš„å“åº”ï¼Œè¯´æ˜æœåŠ¡å·²æˆåŠŸå¯åŠ¨ã€‚

## ğŸ”„ æ›´æ–°ä¸ç»´æŠ¤

### æ›´æ–°åˆ°æœ€æ–°ç‰ˆæœ¬

```bash
# åœæ­¢å½“å‰æœåŠ¡
docker-compose down

# è·å–æœ€æ–°ä»£ç 
git pull

# é‡æ–°æ„å»ºå¹¶å¯åŠ¨
docker-compose up -d --build
```

### æ—¥å¸¸ç»´æŠ¤

```bash
# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose ps

# æŸ¥çœ‹å®æ—¶æ—¥å¿—
docker-compose logs -f

# é‡å¯æœåŠ¡
docker-compose restart

# æŸ¥çœ‹èµ„æºä½¿ç”¨æƒ…å†µ
docker stats
```

### å¤‡ä»½é…ç½®

å»ºè®®å®šæœŸå¤‡ä»½ä½ çš„ `.env` é…ç½®æ–‡ä»¶ï¼š

```bash
cp .env .env.backup.$(date +%Y%m%d)
```

## ğŸ§ª åŠŸèƒ½æµ‹è¯•

ä½¿ç”¨å†…ç½®æµ‹è¯•è„šæœ¬éªŒè¯æ‰€æœ‰åŠŸèƒ½ï¼š

### OpenAI å…¼å®¹æ¥å£æµ‹è¯•

```bash
# 1. é…ç½®æµ‹è¯•è„šæœ¬ä¸­çš„å¯†é’¥
nano test_endpoints.sh
# å°† CLIENT_KEY å’Œ ADMIN_KEY æ›¿æ¢ä¸ºä½  .env æ–‡ä»¶ä¸­çš„å®é™…å¯†é’¥

# 2. èµ‹äºˆæ‰§è¡Œæƒé™
chmod +x test_endpoints.sh

# 3. è¿è¡Œæµ‹è¯•
./test_endpoints.sh
```

### åŸç”Ÿ Gemini API æµ‹è¯•

```bash
# 1. è¿è¡ŒåŸç”Ÿ Gemini API æµ‹è¯•
python3 test_native_gemini_api.py your-client-key

# 2. æˆ–è€…ä½¿ç”¨è¯­æ³•æµ‹è¯•ï¼ˆä¸éœ€è¦çœŸå®å¯†é’¥ï¼‰
python3 syntax_test.py
```

### æµ‹è¯•å†…å®¹

æµ‹è¯•è„šæœ¬ä¼šéªŒè¯ä»¥ä¸‹åŠŸèƒ½ï¼š

**OpenAI å…¼å®¹æ¥å£ï¼š**
- âœ… **æœåŠ¡çŠ¶æ€** - å¥åº·æ£€æŸ¥å’ŒåŸºç¡€è¿æ¥
- âœ… **API å…¼å®¹æ€§** - OpenAI æ ¼å¼çš„æ¨¡å‹åˆ—è¡¨å’ŒèŠå¤©æ¥å£  
- âœ… **æµå¼å“åº”** - å®æ—¶æ•°æ®æµè¾“å‡º
- âœ… **å·¥å…·è°ƒç”¨** - Function Calling åŠŸèƒ½
- âœ… **ç›‘æ§ç«¯ç‚¹** - ç»Ÿè®¡æ•°æ®å’Œæ€§èƒ½æŒ‡æ ‡
- âœ… **ç®¡ç†åŠŸèƒ½** - å¯†é’¥ç®¡ç†å’Œé‡ç½®

**åŸç”Ÿ Gemini APIï¼š**
- âœ… **æ¨¡å‹åˆ—è¡¨** - è·å– Gemini åŸç”Ÿæ ¼å¼çš„æ¨¡å‹ä¿¡æ¯
- âœ… **å†…å®¹ç”Ÿæˆ** - éæµå¼ generateContent æ¥å£
- âœ… **æµå¼ç”Ÿæˆ** - æµå¼ streamGenerateContent æ¥å£  
- âœ… **å·¥å…·è°ƒç”¨** - Gemini åŸç”Ÿå‡½æ•°è°ƒç”¨æ ¼å¼
- âœ… **é”™è¯¯å¤„ç†** - ç»Ÿä¸€çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶

### æ‰‹åŠ¨éªŒè¯

ä¹Ÿå¯ä»¥æ‰‹åŠ¨æµ‹è¯•å…³é”®åŠŸèƒ½ï¼š

**OpenAI å…¼å®¹æ¥å£ï¼š**
```bash
# å¥åº·æ£€æŸ¥
curl http://localhost:8000/health

# è·å–æ¨¡å‹åˆ—è¡¨ï¼ˆéœ€è¦å®¢æˆ·ç«¯å¯†é’¥ï¼‰
curl -H "Authorization: Bearer your-client-key" \
     http://localhost:8000/v1/models

# æµ‹è¯•èŠå¤©åŠŸèƒ½ï¼ˆéœ€è¦å®¢æˆ·ç«¯å¯†é’¥ï¼‰
curl -X POST http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-client-key" \
  -d '{
    "model": "gpt-3.5-turbo",
    "messages": [{"role": "user", "content": "Hello!"}],
    "max_tokens": 50
  }'
```

**åŸç”Ÿ Gemini API æ¥å£ï¼š**
```bash
# è·å– Gemini æ¨¡å‹åˆ—è¡¨
curl -H "X-API-Key: your-client-key" \
     http://localhost:8000/gemini/v1beta/models

# Gemini å¥åº·æ£€æŸ¥
curl http://localhost:8000/gemini/health

# æµ‹è¯• Gemini generateContentï¼ˆéæµå¼ï¼‰
curl -X POST "http://localhost:8000/gemini/v1beta/models/gemini-1.5-flash-latest:generateContent" \
  -H "Content-Type: application/json" \
  -H "X-API-Key: your-client-key" \
  -d '{
    "contents": [
      {
        "role": "user", 
        "parts": [{"text": "Hello! Please introduce yourself."}]
      }
    ],
    "generation_config": {
      "temperature": 0.7,
      "max_output_tokens": 100
    }
  }'

# æµ‹è¯• Gemini streamGenerateContentï¼ˆæµå¼ï¼‰
curl -X POST "http://localhost:8000/gemini/v1beta/models/gemini-1.5-flash-latest:streamGenerateContent" \
  -H "Content-Type: application/json" \
  -H "X-API-Key: your-client-key" \
  -d '{
    "contents": [
      {
        "role": "user", 
        "parts": [{"text": "Count from 1 to 5 slowly."}]
      }
    ],
    "generation_config": {
      "temperature": 0.1
    }
  }'
```

## ğŸ“± ä½¿ç”¨æ–¹æ³•

### OpenAI å…¼å®¹æ¥å£

å°†ä»»ä½•æ”¯æŒ OpenAI API çš„å®¢æˆ·ç«¯æŒ‡å‘ä½ çš„é€‚é…å™¨ï¼š

**é…ç½®å‚æ•°ï¼š**
- **API åœ°å€**: `http://your-server:8000/v1`  
- **API å¯†é’¥**: ä½ çš„ `SECURITY_ADAPTER_API_KEYS` å€¼
- **æ¨¡å‹**: `gpt-3.5-turbo`, `gpt-4`, `gpt-4o` ç­‰

### åŸç”Ÿ Gemini API æ¥å£

å¯¹äºéœ€è¦ä½¿ç”¨ Gemini åŸç”Ÿæ ¼å¼çš„åº”ç”¨ï¼š

**é…ç½®å‚æ•°ï¼š**
- **API åœ°å€**: `http://your-server:8000/gemini/v1beta`  
- **API å¯†é’¥**: ä½ çš„ `SECURITY_ADAPTER_API_KEYS` å€¼
- **æ¨¡å‹**: `gemini-1.5-pro-latest`, `gemini-1.5-flash-latest` ç­‰

### å¸¸è§å®¢æˆ·ç«¯

| å®¢æˆ·ç«¯ | API Base URL è®¾ç½®ä½ç½® |
|--------|---------------------|
| **Cursor** | Settings â†’ Models â†’ Override OpenAI Base URL |
| **JetBrains IDE** | AI Assistant â†’ OpenAI â†’ Custom server URL |
| **Open-WebUI** | Settings â†’ Connections â†’ OpenAI API |
| **ChatGPT Next Web** | Settings â†’ API Host |
| **Gemini CLI** | è®¾ç½® `GEMINI_BASE_URL` ç¯å¢ƒå˜é‡ |
| **Cherry Studio** | Model Provider è®¾ç½®ä¸­çš„ API åœ°å€ |

### Gemini CLI é…ç½®

**Gemini CLI** æ”¯æŒé€šè¿‡ç¯å¢ƒå˜é‡é…ç½®è‡ªå®šä¹‰ API ç«¯ç‚¹ï¼Œå°†è¯·æ±‚é‡å®šå‘åˆ°æœ¬é¡¹ç›®çš„ä»£ç†æœåŠ¡ã€‚

**é…ç½®æ­¥éª¤ï¼š**

1. **è®¾ç½®ç¯å¢ƒå˜é‡** - é…ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡ï¼š
   ```bash
   # è®¾ç½®è‡ªå®šä¹‰ API ç«¯ç‚¹ï¼ˆæŒ‡å‘æœ¬é¡¹ç›®æœåŠ¡ï¼‰
   export GEMINI_BASE_URL="http://localhost:8000/gemini/v1beta"
   
   # è®¾ç½®è®¤è¯å¯†é’¥ï¼ˆä½¿ç”¨æœ¬é¡¹ç›®çš„å®¢æˆ·ç«¯å¯†é’¥ï¼‰
   export GEMINI_API_KEY="your-client-key"  # ä½ çš„ SECURITY_ADAPTER_API_KEYS å€¼
   ```

2. **æŒä¹…åŒ–é…ç½®** - å°†ç¯å¢ƒå˜é‡æ·»åŠ åˆ° shell é…ç½®æ–‡ä»¶ï¼š
   ```bash
   # å¯¹äº bash ç”¨æˆ·
   echo 'export GEMINI_BASE_URL="http://localhost:8000/gemini/v1beta"' >> ~/.bashrc
   echo 'export GEMINI_API_KEY="your-client-key"' >> ~/.bashrc
   source ~/.bashrc
   
   # å¯¹äº zsh ç”¨æˆ·  
   echo 'export GEMINI_BASE_URL="http://localhost:8000/gemini/v1beta"' >> ~/.zshrc
   echo 'export GEMINI_API_KEY="your-client-key"' >> ~/.zshrc
   source ~/.zshrc
   ```

3. **é…ç½®æ–‡ä»¶æ–¹å¼** - æˆ–è€…ä½¿ç”¨ Gemini CLI çš„é…ç½®æ–‡ä»¶ï¼š
   ```bash
   # åˆ›å»ºé…ç½®ç›®å½•
   mkdir -p ~/.gemini
   
   # åˆ›å»ºé…ç½®æ–‡ä»¶
   cat > ~/.gemini/settings.json << EOF
   {
     "base_url": "http://localhost:8000/gemini/v1beta",
     "api_key": "your-client-key"
   }
   EOF
   ```

4. **éªŒè¯é…ç½®** - æµ‹è¯•é…ç½®æ˜¯å¦ç”Ÿæ•ˆï¼š
   ```bash
   # æµ‹è¯•è¿æ¥ï¼ˆå‡è®¾ Gemini CLI å·²å®‰è£…ï¼‰
   gemini models list  # åº”è¯¥é€šè¿‡ä»£ç†æœåŠ¡è·å–æ¨¡å‹åˆ—è¡¨
   ```

**é…ç½®ä¼˜åŠ¿ï¼š**
- âœ… **æ™ºèƒ½å¯†é’¥è½®è¯¢** - è‡ªåŠ¨ä½¿ç”¨å¤šä¸ª Gemini API å¯†é’¥ï¼Œé¿å…å•å¯†é’¥é™é¢
- âœ… **æ•…éšœè‡ªåŠ¨è½¬ç§»** - å¯†é’¥å¤±è´¥æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°å¯ç”¨å¯†é’¥  
- âœ… **æœ¬åœ°åŒ–æ§åˆ¶** - é€šè¿‡æœ¬åœ°ä»£ç†æœåŠ¡ç»Ÿä¸€ç®¡ç†æ‰€æœ‰ Gemini API è¯·æ±‚
- âœ… **å¢å¼ºç¨³å®šæ€§** - å†…ç½®é‡è¯•æœºåˆ¶å’Œå†·å´ä¿æŠ¤

### Cherry Studio é…ç½®

**Cherry Studio** æ˜¯æ”¯æŒå¤šç§ LLM æä¾›å•†çš„æ¡Œé¢å®¢æˆ·ç«¯ï¼Œå¯ä»¥é…ç½®è‡ªå®šä¹‰ API ç«¯ç‚¹æ¥ä½¿ç”¨æœ¬é¡¹ç›®çš„ä»£ç†æœåŠ¡ã€‚

**é…ç½®æ­¥éª¤ï¼š**

1. **æ‰“å¼€è®¾ç½®ç•Œé¢**ï¼š
   - å¯åŠ¨ Cherry Studio åº”ç”¨
   - ç‚¹å‡»å·¦ä¸‹è§’çš„ "Settings"ï¼ˆè®¾ç½®ï¼‰æŒ‰é’®
   - é€‰æ‹© "Model Provider"ï¼ˆæ¨¡å‹æä¾›å•†ï¼‰é€‰é¡¹

2. **æ·»åŠ è‡ªå®šä¹‰æä¾›å•†**ï¼š
   - ç‚¹å‡»å³ä¸Šè§’çš„ "+" æŒ‰é’®æ·»åŠ æ–°çš„æä¾›å•†
   - é€‰æ‹© "OpenAI Compatible" æˆ– "Custom Endpoint" ç±»å‹

3. **é…ç½® API å‚æ•°**ï¼š
   ```
   Provider Name: Gemini Converter (è‡ªå®šä¹‰åç§°)
   API Base URL: http://localhost:8000/v1
   API Key: your-client-key  # ä½ çš„ SECURITY_ADAPTER_API_KEYS å€¼
   Model Names: gpt-3.5-turbo,gpt-4,gpt-4o  # æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
   ```

4. **é«˜çº§é…ç½®ï¼ˆå¯é€‰ï¼‰**ï¼š
   - **Stream Support**: å¯ç”¨æµå¼å“åº”
   - **Function Calling**: å¯ç”¨å·¥å…·è°ƒç”¨åŠŸèƒ½
   - **JSON Mode**: å¯ç”¨ JSON æ ¼å¼å“åº”
   - **Custom Headers**: å¦‚éœ€è¦å¯æ·»åŠ è‡ªå®šä¹‰è¯·æ±‚å¤´

5. **ä¿å­˜å¹¶æµ‹è¯•**ï¼š
   - ç‚¹å‡» "Save" ä¿å­˜é…ç½®
   - åœ¨å¯¹è¯ç•Œé¢é€‰æ‹©æ–°é…ç½®çš„æä¾›å•†
   - å‘é€æµ‹è¯•æ¶ˆæ¯éªŒè¯è¿æ¥

**åŸç”Ÿ Gemini æ ¼å¼é…ç½®ï¼ˆé«˜çº§ï¼‰**ï¼š
å¯¹äºéœ€è¦ä½¿ç”¨ Gemini åŸç”Ÿ API æ ¼å¼çš„åœºæ™¯ï¼š
```
Provider Name: Gemini Native
API Base URL: http://localhost:8000/gemini/v1beta
API Key: your-client-key
Authentication: X-API-Key Header
Model Names: gemini-1.5-pro-latest,gemini-1.5-flash-latest
```

**é…ç½®ä¼˜åŠ¿ï¼š**
- âœ… **å¤šå¯†é’¥è½®è¯¢** - äº«å—æœ¬é¡¹ç›®çš„æ™ºèƒ½å¯†é’¥ç®¡ç†
- âœ… **ç»Ÿä¸€ç•Œé¢** - åœ¨ Cherry Studio ä¸­ä½¿ç”¨æ‰€æœ‰ Gemini æ¨¡å‹
- âœ… **å¢å¼ºç¨³å®šæ€§** - é€šè¿‡ä»£ç†æœåŠ¡æä¾›çš„é‡è¯•å’Œæ•…éšœè½¬ç§»æœºåˆ¶
- âœ… **æœ¬åœ°æ§åˆ¶** - å®Œå…¨æŒæ§ API è¯·æ±‚çš„è·¯ç”±å’Œç®¡ç†

### ç¼–ç¨‹æ¥å£

ä½¿ç”¨ä»»ä½• OpenAI å®¢æˆ·ç«¯åº“ï¼Œåªéœ€ä¿®æ”¹ base_urlï¼š

**Python (openai åº“) - OpenAI å…¼å®¹**
```python
import openai

client = openai.OpenAI(
    base_url="http://localhost:8000/v1",
    api_key="your-client-key"  # ä½ çš„ SECURITY_ADAPTER_API_KEYS
)

response = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[{"role": "user", "content": "Hello!"}]
)
```

**Python - åŸç”Ÿ Gemini API æ ¼å¼**
```python
import requests
import json

def call_gemini_api(content: str, model: str = "gemini-1.5-flash-latest"):
    url = f"http://localhost:8000/gemini/v1beta/models/{model}:generateContent"
    headers = {
        "Content-Type": "application/json",
        "X-API-Key": "your-client-key"  # ä½ çš„ SECURITY_ADAPTER_API_KEYS
    }
    data = {
        "contents": [
            {
                "role": "user",
                "parts": [{"text": content}]
            }
        ],
        "generation_config": {
            "temperature": 0.7,
            "max_output_tokens": 1000
        }
    }
    
    response = requests.post(url, headers=headers, json=data)
    return response.json()

# ä½¿ç”¨ç¤ºä¾‹
result = call_gemini_api("Hello! How are you?")
if result.get("candidates"):
    text = result["candidates"][0]["content"]["parts"][0]["text"]
    print(text)
```

**Python - åŸç”Ÿ Gemini æµå¼å“åº”**
```python
import requests
import json

def stream_gemini_api(content: str, model: str = "gemini-1.5-flash-latest"):
    url = f"http://localhost:8000/gemini/v1beta/models/{model}:streamGenerateContent"
    headers = {
        "Content-Type": "application/json",
        "X-API-Key": "your-client-key"
    }
    data = {
        "contents": [
            {
                "role": "user",
                "parts": [{"text": content}]
            }
        ],
        "generation_config": {
            "temperature": 0.7
        }
    }
    
    with requests.post(url, headers=headers, json=data, stream=True) as response:
        for line in response.iter_lines():
            if line:
                try:
                    chunk_data = json.loads(line.decode('utf-8'))
                    if chunk_data.get("candidates"):
                        candidate = chunk_data["candidates"][0]
                        if "content" in candidate and "parts" in candidate["content"]:
                            for part in candidate["content"]["parts"]:
                                if "text" in part:
                                    print(part["text"], end="", flush=True)
                except json.JSONDecodeError:
                    continue
        print()  # æ¢è¡Œ

# ä½¿ç”¨ç¤ºä¾‹
stream_gemini_api("Please count from 1 to 10.")
```

**JavaScript/Node.js - OpenAI å…¼å®¹**
```javascript
import OpenAI from 'openai';

const openai = new OpenAI({
    baseURL: 'http://localhost:8000/v1',
    apiKey: 'your-client-key'  // ä½ çš„ SECURITY_ADAPTER_API_KEYS
});

const response = await openai.chat.completions.create({
    model: 'gpt-3.5-turbo',
    messages: [{ role: 'user', content: 'Hello!' }]
});
```

**JavaScript - åŸç”Ÿ Gemini API æ ¼å¼**
```javascript
async function callGeminiAPI(content, model = 'gemini-1.5-flash-latest') {
    const url = `http://localhost:8000/gemini/v1beta/models/${model}:generateContent`;
    const headers = {
        'Content-Type': 'application/json',
        'X-API-Key': 'your-client-key'  // ä½ çš„ SECURITY_ADAPTER_API_KEYS
    };
    const data = {
        contents: [
            {
                role: 'user',
                parts: [{ text: content }]
            }
        ],
        generation_config: {
            temperature: 0.7,
            max_output_tokens: 1000
        }
    };
    
    const response = await fetch(url, {
        method: 'POST',
        headers: headers,
        body: JSON.stringify(data)
    });
    
    return await response.json();
}

// ä½¿ç”¨ç¤ºä¾‹
const result = await callGeminiAPI("Hello! How are you?");
if (result.candidates && result.candidates.length > 0) {
    const text = result.candidates[0].content.parts[0].text;
    console.log(text);
}
```

### æ”¯æŒåŠŸèƒ½

**OpenAI å…¼å®¹æ¥å£ï¼š**
- âœ… **èŠå¤©å¯¹è¯** - `/v1/chat/completions`
- âœ… **æµå¼å“åº”** - `stream: true`
- âœ… **å·¥å…·è°ƒç”¨** - Function Calling
- âœ… **æ¨¡å‹åˆ—è¡¨** - `/v1/models`
- âœ… **JSON æ¨¡å¼** - `response_format: {"type": "json_object"}`

**åŸç”Ÿ Gemini API æ¥å£ï¼š**
- âœ… **å†…å®¹ç”Ÿæˆ** - `/gemini/v1beta/models/{model}:generateContent`
- âœ… **æµå¼ç”Ÿæˆ** - `/gemini/v1beta/models/{model}:streamGenerateContent`
- âœ… **æ¨¡å‹åˆ—è¡¨** - `/gemini/v1beta/models`
- âœ… **å‡½æ•°è°ƒç”¨** - Native Gemini function calling format
- âœ… **å®‰å…¨è®¾ç½®** - Safety settings and content filtering
- âœ… **ç”Ÿæˆé…ç½®** - Temperature, top_p, top_k, max_output_tokens

## ğŸ”§ æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜

**æœåŠ¡æ— æ³•å¯åŠ¨**
```bash
# æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨
lsof -i :8000

# æŸ¥çœ‹è¯¦ç»†é”™è¯¯æ—¥å¿—
docker-compose logs gemini-converter-adapter

# æ£€æŸ¥é…ç½®æ–‡ä»¶
cat .env | grep -v "^#"
```

**API å¯†é’¥é—®é¢˜**
```bash
# éªŒè¯ Gemini API å¯†é’¥
docker-compose run --rm gemini-converter-adapter python api_key_checker.py

# æ£€æŸ¥å¯†é’¥æ ¼å¼ï¼ˆä¸åº”åŒ…å«å¼•å·æˆ–ç©ºæ ¼ï¼‰
grep "GEMINI_API_KEYS" .env
```

**è¿æ¥è¶…æ—¶æˆ–è¯·æ±‚å¤±è´¥**
```bash
# æ£€æŸ¥ç½‘ç»œè¿æ¥
curl -I https://generativelanguage.googleapis.com

# æŸ¥çœ‹å®æ—¶è¯·æ±‚æ—¥å¿—
docker-compose logs -f --tail 100

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
curl http://localhost:8000/health
```

### è¯Šæ–­å·¥å…·

**å¥åº·æ£€æŸ¥è„šæœ¬**
```bash
# è¿è¡Œå®Œæ•´è¯Šæ–­
docker-compose run --rm gemini-converter-adapter python diagnose_script.py
```

**æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯**
```bash
# ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯ï¼ˆåŒ…å«æ€§èƒ½æŒ‡æ ‡ï¼‰
curl -H "Authorization: Bearer your-client-key" \
     http://localhost:8000/stats
```

### æ€§èƒ½ä¼˜åŒ–

**è°ƒæ•´å¹¶å‘æ•°**
```bash
# åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®
SERVICE_WORKERS=4  # æ ¹æ® CPU æ ¸å¿ƒæ•°è°ƒæ•´
```

**å¯ç”¨ç¼“å­˜**
```bash
# åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®
CACHE_ENABLED=True
CACHE_MAX_SIZE=1000
CACHE_TTL=300
```

## ğŸ“¡ API ç«¯ç‚¹

### OpenAI å…¼å®¹æ¥å£

| ç«¯ç‚¹ | ç”¨é€” | è®¤è¯è¦æ±‚ |
|------|------|----------|
| `GET /health` | æœåŠ¡å¥åº·æ£€æŸ¥ | æ—  |
| `GET /v1/models` | è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼ˆOpenAIæ ¼å¼ï¼‰ | å®¢æˆ·ç«¯å¯†é’¥ |
| `POST /v1/chat/completions` | èŠå¤©å¯¹è¯æ¥å£ï¼ˆOpenAIæ ¼å¼ï¼‰ | å®¢æˆ·ç«¯å¯†é’¥ |
| `GET /stats` | æŸ¥çœ‹ä½¿ç”¨ç»Ÿè®¡ | å®¢æˆ·ç«¯å¯†é’¥ |

### åŸç”Ÿ Gemini API æ¥å£

| ç«¯ç‚¹ | ç”¨é€” | è®¤è¯è¦æ±‚ |
|------|------|----------|
| `GET /gemini/health` | Gemini API å¥åº·æ£€æŸ¥ | æ—  |
| `GET /gemini/v1beta/models` | è·å– Gemini æ¨¡å‹åˆ—è¡¨ï¼ˆåŸç”Ÿæ ¼å¼ï¼‰ | å®¢æˆ·ç«¯å¯†é’¥ |
| `POST /gemini/v1beta/models/{model}:generateContent` | å†…å®¹ç”Ÿæˆï¼ˆéæµå¼ï¼ŒåŸç”Ÿæ ¼å¼ï¼‰ | å®¢æˆ·ç«¯å¯†é’¥ |
| `POST /gemini/v1beta/models/{model}:streamGenerateContent` | å†…å®¹ç”Ÿæˆï¼ˆæµå¼ï¼ŒåŸç”Ÿæ ¼å¼ï¼‰ | å®¢æˆ·ç«¯å¯†é’¥ |

### ç®¡ç†æ¥å£

| ç«¯ç‚¹ | ç”¨é€” | è®¤è¯è¦æ±‚ |
|------|------|----------|
| `POST /admin/keys` | åŠ¨æ€æ·»åŠ  API å¯†é’¥ | ç®¡ç†å‘˜å¯†é’¥ |
| `DELETE /admin/keys` | åŠ¨æ€ç§»é™¤ API å¯†é’¥ | ç®¡ç†å‘˜å¯†é’¥ |
| `PUT /admin/keys/{key_id}` | æ›´æ–°å¯†é’¥çŠ¶æ€ | ç®¡ç†å‘˜å¯†é’¥ |

### è®¤è¯æ–¹å¼

**å®¢æˆ·ç«¯å¯†é’¥** - æ”¯æŒä¸¤ç§æ ¼å¼ï¼š
```bash
# Bearer Token æ ¼å¼ï¼ˆæ¨èç”¨äº OpenAI å…¼å®¹æ¥å£ï¼‰
curl -H "Authorization: Bearer your-client-key" http://localhost:8000/v1/models

# X-API-Key Header æ ¼å¼ï¼ˆæ¨èç”¨äº Gemini åŸç”Ÿæ¥å£ï¼‰
curl -H "X-API-Key: your-client-key" http://localhost:8000/gemini/v1beta/models
```

**ç®¡ç†å‘˜å¯†é’¥** (X-API-Key Header)
```bash
curl -H "X-API-Key: your-admin-key" http://localhost:8000/admin/keys
```

### Swagger/OpenAPI æ–‡æ¡£

æœåŠ¡å¯åŠ¨åï¼Œå¯è®¿é—®ä»¥ä¸‹åœ°å€æŸ¥çœ‹å®Œæ•´çš„ API æ–‡æ¡£ï¼š

- **Swagger UI**: `http://localhost:8000/docs`
- **ReDoc**: `http://localhost:8000/redoc`

è¿™äº›æ–‡æ¡£åŒ…å«äº†æ‰€æœ‰ç«¯ç‚¹çš„è¯¦ç»†è¯´æ˜ã€è¯·æ±‚/å“åº”æ ¼å¼å’Œäº¤äº’å¼æµ‹è¯•åŠŸèƒ½ã€‚

---

## ğŸ“„ è®¸å¯è¯

MIT License - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Request æ¥æ”¹è¿›è¿™ä¸ªé¡¹ç›®ï¼

## ğŸ“ æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·åœ¨ GitHub ä¸Šåˆ›å»º [Issue](https://github.com/tellerlin/gemini-converter/issues)

